{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_adm = gpd.read_file('../data/ADM_Shp/selected_distict_mauza.shp').to_crs('EPSG:4326')\n",
    "df_summary = pd.read_csv('../data/FE_Results/June_Aug/MAUZ_flood_summary_QA.csv')\n",
    "df_survey = pd.read_csv('../data/CDP_Survey/household_locations_impactevaluation_matched_floodlevel_exposure.csv')\n",
    "df_ts_sent = pd.read_csv('../data/FE_Results/June_Aug/MAUZ_flood_extent_sentinel.csv')\n",
    "df_ts_interp = pd.read_csv('../data/FE_Results/June_Aug/MAUZ_flood_extent_interpolated.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rename some of the columns to standardize them across datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary = df_summary.rename(columns={'COV': 'ERR', 'PCODE': 'OBJECTID'})\n",
    "df_ts_interp = df_ts_interp.rename(columns={'PCODE': 'OBJECTID', 'FLOOD_EXTENT': 'FLOOD_FRACTION', 'date': 'DATE'})\n",
    "df_ts_sent = df_ts_sent.rename(columns={'MAUZ_PCODE': 'OBJECTID', 'flooded_fraction': 'FLOOD_FRACTION', 'date': 'DATE'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add some of the additional QA flag columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary['PEAK_DIFF'] = abs(df_summary['DIFF_SAT'])>20\n",
    "df_summary['ERR_ERR'] = df_summary['ERR']>20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll subset the results to just the mauzas that have survey data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_mauz = set(df_survey['OBJECTID'])\n",
    "df_summary_survey = df_summary[df_summary['OBJECTID'].isin(survey_mauz)]\n",
    "assert len(df_summary_survey.index)==len(survey_mauz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also subset both of the time series datasets by the mauzas in the survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts_sent_survey = df_ts_sent[df_ts_sent['OBJECTID'].isin(survey_mauz)]\n",
    "assert len(set(df_ts_sent_survey.OBJECTID)) == len(survey_mauz)\n",
    "df_ts_sent_survey.to_csv('../data/FE_Results/June_Aug/MAUZ_flood_extent_sentinel_survey.csv', index=False)\n",
    "\n",
    "df_ts_interp_survey = df_ts_interp[df_ts_interp['OBJECTID'].isin(survey_mauz)]\n",
    "assert len(set(df_ts_interp_survey.OBJECTID)) == len(survey_mauz)\n",
    "df_ts_interp_survey.to_csv('../data/FE_Results/June_Aug/MAUZ_flood_extent_interpolated_survey.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's count the number of mauzas that have problems with the Gaussian fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3\n0\n1\n1\n1\n1\n4\n"
     ]
    }
   ],
   "source": [
    "print(df_summary_survey.NO_FIT.sum())\n",
    "print(df_summary_survey.NEG.sum())\n",
    "print(df_summary_survey.RIVER.sum())\n",
    "print(df_summary_survey.FWHM_ERR.sum())\n",
    "print(df_summary_survey.MAX_DIFF.sum())\n",
    "print(df_summary_survey.PEAK_DIFF.sum())\n",
    "print(df_summary_survey.ERR_ERR.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the centroid of each mauza and join this in with the survey data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_adm = gdf_adm.to_crs('EPSG:32646')\n",
    "gdf_adm['centroid'] = gdf_adm.centroid\n",
    "gdf_adm = gdf_adm.set_geometry('centroid')\n",
    "gdf_adm = gdf_adm.to_crs('EPSG:4326')\n",
    "gdf_adm['LAT'] = gdf_adm['centroid'].y\n",
    "gdf_adm['LON'] = gdf_adm['centroid'].x\n",
    "df_summary_survey = df_summary_survey.merge(gdf_adm[['OBJECTID', 'LAT', 'LON']], left_on='OBJECTID', right_on='OBJECTID', how='left')\n",
    "df_summary_survey = df_summary_survey.drop(columns=['OBJECTID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        ERR  DIFF_SAT  FWHM  MAX_SAT      PEAK_G    PEAK_SAT      RMSE  \\\n",
       "0  1.808677       6.0  25.0   0.1145  2020-07-15  2020-07-21  0.018582   \n",
       "1  3.122185       0.0  27.0   0.0653  2020-07-21  2020-07-21  0.013396   \n",
       "2  3.678658       0.0  33.0   0.1253  2020-07-21  2020-07-21  0.029337   \n",
       "3  2.594886       1.0  23.0   0.0698  2020-07-26  2020-07-27  0.013669   \n",
       "4  1.789581       2.0  30.0   0.1427  2020-07-19  2020-07-21  0.020128   \n",
       "\n",
       "      MAX_G  NO_FIT    NEG  RIVER  FWHM_ERR  MAX_DIFF  PEAK_DIFF  ERR_ERR  \\\n",
       "0  0.088123   False  False  False     False     False      False    False   \n",
       "1  0.041417   False  False  False     False     False      False    False   \n",
       "2  0.085286   False  False  False     False     False      False    False   \n",
       "3  0.042601   False  False  False     False     False      False    False   \n",
       "4  0.114673   False  False  False     False     False      False    False   \n",
       "\n",
       "         LAT        LON  \n",
       "0  26.214270  89.655010  \n",
       "1  26.195581  89.657720  \n",
       "2  26.181015  89.680440  \n",
       "3  26.185698  89.640361  \n",
       "4  26.171229  89.666350  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ERR</th>\n      <th>DIFF_SAT</th>\n      <th>FWHM</th>\n      <th>MAX_SAT</th>\n      <th>PEAK_G</th>\n      <th>PEAK_SAT</th>\n      <th>RMSE</th>\n      <th>MAX_G</th>\n      <th>NO_FIT</th>\n      <th>NEG</th>\n      <th>RIVER</th>\n      <th>FWHM_ERR</th>\n      <th>MAX_DIFF</th>\n      <th>PEAK_DIFF</th>\n      <th>ERR_ERR</th>\n      <th>LAT</th>\n      <th>LON</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.808677</td>\n      <td>6.0</td>\n      <td>25.0</td>\n      <td>0.1145</td>\n      <td>2020-07-15</td>\n      <td>2020-07-21</td>\n      <td>0.018582</td>\n      <td>0.088123</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>26.214270</td>\n      <td>89.655010</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.122185</td>\n      <td>0.0</td>\n      <td>27.0</td>\n      <td>0.0653</td>\n      <td>2020-07-21</td>\n      <td>2020-07-21</td>\n      <td>0.013396</td>\n      <td>0.041417</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>26.195581</td>\n      <td>89.657720</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.678658</td>\n      <td>0.0</td>\n      <td>33.0</td>\n      <td>0.1253</td>\n      <td>2020-07-21</td>\n      <td>2020-07-21</td>\n      <td>0.029337</td>\n      <td>0.085286</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>26.181015</td>\n      <td>89.680440</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.594886</td>\n      <td>1.0</td>\n      <td>23.0</td>\n      <td>0.0698</td>\n      <td>2020-07-26</td>\n      <td>2020-07-27</td>\n      <td>0.013669</td>\n      <td>0.042601</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>26.185698</td>\n      <td>89.640361</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.789581</td>\n      <td>2.0</td>\n      <td>30.0</td>\n      <td>0.1427</td>\n      <td>2020-07-19</td>\n      <td>2020-07-21</td>\n      <td>0.020128</td>\n      <td>0.114673</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>26.171229</td>\n      <td>89.666350</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "df_summary_survey.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_survey.to_csv('../data/FE_Results/June_Aug/MAUZ_flood_summary_QA_survey.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bang_floods",
   "language": "python",
   "name": "bang_floods"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}