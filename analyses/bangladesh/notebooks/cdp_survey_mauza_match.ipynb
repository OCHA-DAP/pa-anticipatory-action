{
 "cells": [
  {
   "source": [
    "Noteboook to test the Fuzzywuzzy library https://github.com/seatgeek/fuzzywuzzy for geolocation of the survey data.\n",
    "All input datasets available from Google Drive https://drive.google.com/drive/u/1/folders/18IIHhX2NVjRd6X96-UEAdZB2FwdaR9rw should be placed in the folder ./mauza_data/"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "from fuzzywuzzy import fuzz\n",
    "import numpy as np\n",
    "\n",
    "dir_path = os.path.dirname(os.path.realpath('__file__'))\n",
    "df_srv=pd.read_excel(f'{dir_path}/mauza_data/household_locations_impactevaluation.xlsx',sheet_name='Sheet1')\n",
    "# removing asterisk from Mouza names in survey data\n",
    "df_srv['C04_mouza_name']=df_srv['C04_mouza_name'].replace('\\*','',regex=True).astype(str)\n",
    "df_shp=gpd.read_file(f'{dir_path}/mauza_data/mauza_shp/selected_distict_mauza.shp')"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": []
  },
  {
   "source": [
    "In order to reduce duplicates we need to use the full combination df admin names\n",
    "In the shapefile even the combination of Mauza, Union, Upazilla and District is still not always unique.\n",
    "This is in many cases due to issues in the inputs shapefile. It doesn't impact too much the statistical analysis as they would be in the same area."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MAUZNAME        UNINAME       THANAME        DISTNAME   \nRahmatpur       Patgram       Patgram        Lalmonirhat    4.0\nDattagram       Digalkandi    Ghatail        Tangail        2.0\nPurli Hasan     Digar         Ghatail        Tangail        2.0\nMadarpur        Sapmara       Gobindaganj    Gaibandha      2.0\nKanda Para      Dhankora      Saturia        Manikganj      2.0\n                                                           ... \nBil Kedar Khas  Lakshmikundi  Ishwardi       Pabna          2.0\nSener Gagarjan  Magra         Tangail Sadar  Tangail        2.0\nArmasuka        Mirkutia      Chauhali       Sirajganj      2.0\nPar Magra       Magra         Tangail Sadar  Tangail        2.0\nChak Bheka      Chatra        Pirganj        Rangpur        2.0\nLength: 72, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "duplicate_mozas=df_shp[['MAUZNAME','UNINAME','THANAME','DISTNAME']].value_counts()\n",
    "duplicate_mozas=duplicate_mozas.where(duplicate_mozas>1).dropna()\n",
    "print(duplicate_mozas)"
   ]
  },
  {
   "source": [
    "We create a new string that is the combination of Mauza, Union, Upazilla and District names, both for the survey data and for the shapefile "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_shp=['MAUZNAME','UNINAME','THANAME','DISTNAME']\n",
    "cols_srv=['C04_mouza_name','C04_union_name','C04_upazila_name','C04_district_name']\n",
    "\n",
    "df_shp[cols_shp]=df_shp[cols_shp].astype(str)\n",
    "df_srv[cols_srv]=df_srv[cols_srv].astype(str)\n",
    "\n",
    "df_shp['shp_full_name']= df_shp[cols_shp].agg(','.join, axis=1)\n",
    "df_srv['srv_full_name']= df_srv[cols_srv].agg(','.join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_best_fuzzy_match(srv_name,df_shp,threshold=70):\n",
    "# returns the best match for srv_name among all the features in the shapefile\n",
    "# the features with the highest score above the threshold is returned\n",
    "# if there are multiple matches it selects the feature with the largest area\n",
    "# if there are no matching features returns None\n",
    "# the fuzzy matching is done usind scores from https://github.com/seatgeek/fuzzywuzzy\n",
    "    \n",
    "    # calculate all fuzzy scores relative to srv_name\n",
    "    scores = df_shp['shp_full_name'].apply(lambda x: fuzz.ratio(x,srv_name))\n",
    "    # create a dataframe to perform some operations\n",
    "    data = pd.DataFrame(\n",
    "            {'shp_id': df_shp['OBJECTID'],\n",
    "            'shp_area': df_shp['Shape_Area'],\n",
    "            'shp_full_name': df_shp['shp_full_name'],\n",
    "            'fuzzy_score': scores}\n",
    "            )\n",
    "    max_score=data['fuzzy_score'].max()\n",
    "    if max_score<threshold:\n",
    "        return {\n",
    "                'srv_full_name':srv_name,\n",
    "                'n_matches':0,\n",
    "                'matching_score':max_score\n",
    "                }\n",
    "    # get only results with maximum scores\n",
    "    data=data.loc[data['fuzzy_score']==max_score]\n",
    "    n_matches=len(data)\n",
    "    # if there are multiple choices we get the largest one\n",
    "    data=data.loc[data['shp_area'].idxmax()]\n",
    "    return {\n",
    "            'srv_full_name':srv_name,\n",
    "            'shp_id':data['shp_id'],\n",
    "            'shp_full_name':data['shp_full_name'],\n",
    "            'n_matches':n_matches,\n",
    "            'matching_score':max_score\n",
    "            }"
   ]
  },
  {
   "source": [
    "Using the function defined above we can now match the survey names (srv_name) with the corresponding name in teh shapefile and the OBJECTID of the shapefile feature\n",
    "We are only matching the set of survey names to speed up computing time"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_srv_full_name=df_srv['srv_full_name'].unique()\n",
    "matching_df=pd.DataFrame()\n",
    "# TODO put in function\n",
    "for srv_full_name in set_srv_full_name:\n",
    "    matching_df=matching_df.append(get_best_fuzzy_match(srv_full_name,df_shp),ignore_index=True)"
   ]
  },
  {
   "source": [
    "We can finally do a left join on the survey data to get the OBJECTID of the shapefile associated"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "total rows:9130\nmultiple matches: 62\nNo matches: 0\n"
     ]
    }
   ],
   "source": [
    "matched_srv=pd.merge(left=df_srv,right=matching_df,left_on='srv_full_name',right_on='srv_full_name',how='left')\n",
    "\n",
    "# check total #of rows\n",
    "print(f'total rows:{len(matched_srv)}')\n",
    "\n",
    "# check multiple matches\n",
    "print('multiple matches: {}'.format(len(matched_srv[matched_srv['n_matches']>1])))\n",
    "\n",
    "# check no matches\n",
    "print('No matches: {}'.format(len(matched_srv[matched_srv['n_matches']==0])))\n"
   ]
  },
  {
   "source": [
    "We can finally merge back the shapefile and see # of people per union and district to see if it matches the inputs\n",
    "This is done using the RECONSTRUCTED geolocation and it's useful to cross check the quality of the geolocation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of interviewees by district\n",
      "DISTNAME\n",
      "Gaibandha    2562\n",
      "Jamalpur      905\n",
      "Kurigram     4518\n",
      "Sirajganj    1145\n",
      "dtype: int64\n",
      "Number of interviewees by union\n",
      "UNINAME\n",
      "Andhari Jhar       20\n",
      "Ashtamir Char      46\n",
      "Bahadurabad        99\n",
      "Ballabher Khas     82\n",
      "Bamandanga         67\n",
      "                 ... \n",
      "Thanahat           64\n",
      "Thetroy            79\n",
      "Tilai              17\n",
      "Udakhali          149\n",
      "Uria              121\n",
      "Length: 110, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "matched_srv_shp=pd.merge(left=matched_srv,right=df_shp,left_on='shp_id',right_on='OBJECTID',how='left',suffixes=['','_shp'])\n",
    "matched_srv_shp=matched_srv_shp.drop(['shp_full_name_shp','geometry'],axis=1)\n",
    "\n",
    "\n",
    "print('Number of interviewees by district')\n",
    "print(matched_srv_shp.groupby('DISTNAME').size())\n",
    "\n",
    "print('Number of interviewees by union')\n",
    "print(matched_srv_shp.groupby('UNINAME').size())\n",
    "\n",
    "writer = pd.ExcelWriter(f'{dir_path}/mauza_data/household_locations_impactevaluation_matched.xlsx', engine='xlsxwriter')\n",
    "\n",
    "matched_srv_shp.to_excel(writer,sheet_name='matched_data')\n",
    "matched_srv_shp.groupby('DISTNAME').size().to_excel(writer,sheet_name='QA_HH_District')\n",
    "matched_srv_shp.groupby('UNINAME').size().to_excel(writer,sheet_name='QA_HH_Union')\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "ad6a703b152e2e87198901afbb29ccb0d68000e0d2979fe6beceb74cf6f11ed2"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}