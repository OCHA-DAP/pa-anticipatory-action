{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.environ['AA_DATA_DIR']\n",
    "bgd_dir = os.path.join(data_dir, 'exploration', 'bangladesh')\n",
    "\n",
    "gdf_adm = gpd.read_file(os.path.join(bgd_dir, 'ADM_Shp/selected_distict_mauza.shp')).to_crs('EPSG:4326')\n",
    "df_summary = pd.read_csv(os.path.join(bgd_dir, 'FE_Results/June_Aug/MAUZ_flood_summary_QA.csv'))\n",
    "df_survey = pd.read_csv(os.path.join(bgd_dir, 'CDP_Survey/household_locations_impactevaluation_landtype.csv'))\n",
    "df_ts_sent = pd.read_csv(os.path.join(bgd_dir, 'FE_Results/June_Aug/MAUZ_flood_extent_sentinel.csv'))\n",
    "df_ts_interp = pd.read_csv(os.path.join(bgd_dir, 'FE_Results/June_Aug/MAUZ_flood_extent_interpolated.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rename some of the columns to standardize them across datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary = df_summary.rename(columns={'COV': 'ERR', 'PCODE': 'OBJECTID'})\n",
    "df_ts_interp = df_ts_interp.rename(columns={'PCODE': 'OBJECTID', 'FLOOD_EXTENT': 'FLOOD_FRACTION', 'date': 'DATE'})\n",
    "df_ts_sent = df_ts_sent.rename(columns={'MAUZ_PCODE': 'OBJECTID', 'flooded_fraction': 'FLOOD_FRACTION', 'date': 'DATE'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add some of the additional QA flag columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary['PEAK_DIFF'] = abs(df_summary['DIFF_SAT'])>20\n",
    "df_summary['ERR_ERR'] = df_summary['ERR']>20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll subset the results to just the mauzas that have survey data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_mauz = set(df_survey['OBJECTID'])\n",
    "df_summary_survey = df_summary[df_summary['OBJECTID'].isin(survey_mauz)]\n",
    "assert len(df_summary_survey.index)==len(survey_mauz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also subset both of the time series datasets by the mauzas in the survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts_sent_survey = df_ts_sent[df_ts_sent['OBJECTID'].isin(survey_mauz)]\n",
    "assert len(set(df_ts_sent_survey.OBJECTID)) == len(survey_mauz)\n",
    "df_ts_sent_survey.to_csv(os.path.join(bgd_dir, 'FE_Results/June_Aug/MAUZ_flood_extent_sentinel_survey.csv'), index=False)\n",
    "\n",
    "df_ts_interp_survey = df_ts_interp[df_ts_interp['OBJECTID'].isin(survey_mauz)]\n",
    "assert len(set(df_ts_interp_survey.OBJECTID)) == len(survey_mauz)\n",
    "df_ts_interp_survey.to_csv(os.path.join(bgd_dir, 'FE_Results/June_Aug/MAUZ_flood_extent_interpolated_survey.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's count the number of mauzas that have problems with the Gaussian fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_summary_survey.NO_FIT.sum())\n",
    "print(df_summary_survey.NEG.sum())\n",
    "print(df_summary_survey.RIVER.sum())\n",
    "print(df_summary_survey.FWHM_ERR.sum())\n",
    "print(df_summary_survey.MAX_DIFF.sum())\n",
    "print(df_summary_survey.PEAK_DIFF.sum())\n",
    "print(df_summary_survey.ERR_ERR.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the centroid of each mauza and join this in with the survey data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_adm = gdf_adm.to_crs('EPSG:32646')\n",
    "gdf_adm['centroid'] = gdf_adm.centroid\n",
    "gdf_adm = gdf_adm.set_geometry('centroid')\n",
    "gdf_adm = gdf_adm.to_crs('EPSG:4326')\n",
    "gdf_adm['LAT'] = gdf_adm['centroid'].y\n",
    "gdf_adm['LON'] = gdf_adm['centroid'].x\n",
    "df_summary_survey = df_summary_survey.merge(gdf_adm[['OBJECTID', 'LAT', 'LON']], left_on='OBJECTID', right_on='OBJECTID', how='left')\n",
    "#df_summary_survey = df_summary_survey.drop(columns=['OBJECTID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_survey.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_survey.to_csv(os.path.join(bgd_dir, 'FE_Results/June_Aug/MAUZ_flood_summary_QA_survey.csv', index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bang_floods",
   "language": "python",
   "name": "bang_floods"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
